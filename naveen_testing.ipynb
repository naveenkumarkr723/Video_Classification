{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naveen kumar jadi\n"
     ]
    }
   ],
   "source": [
    "print(\"Naveen kumar jadi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "FRAME_COUNT = 16  # Number of frames per video\n",
    "IMAGE_SIZE = 112  # Resize frame to 112x112\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 4  # Only four classes: cricket, soccer, baseball, basketball\n",
    "SPORTS_CLASSES = [\"Cricket\", \"Soccer\", \"Baseball\", \"Basketball\"]\n",
    "\n",
    "# Path to dataset folder\n",
    "DATASET_PATH = \"/Users/naveenjadi/Desktop/naveen/naveen_experiments/videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path, frame_count=FRAME_COUNT):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "\n",
    "    interval = max(total_frames // frame_count, 1)  # Sample evenly across the video\n",
    "    for i in range(frame_count):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        frames.append(frame / 255.0)  # Normalize pixel values\n",
    "    cap.release()\n",
    "\n",
    "    # Pad with black frames if video has fewer frames\n",
    "    while len(frames) < frame_count:\n",
    "        frames.append(np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "def load_dataset(data_path, frame_count=FRAME_COUNT):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    class_map = {SPORTS_CLASSES[i]: i for i in range(len(SPORTS_CLASSES))}\n",
    "\n",
    "    for cls_name in SPORTS_CLASSES:\n",
    "        cls_path = os.path.join(data_path, cls_name)\n",
    "        for video_file in os.listdir(cls_path):\n",
    "            video_path = os.path.join(cls_path, video_file)\n",
    "            frames = extract_frames(video_path, frame_count)\n",
    "            videos.append(frames)\n",
    "            labels.append(class_map[cls_name])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    videos = np.array(videos)\n",
    "    labels = to_categorical(labels, num_classes=len(SPORTS_CLASSES))\n",
    "    return train_test_split(videos, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load data\n",
    "train_x, test_x, train_y, test_y = load_dataset(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3D CNN Model\n",
    "def build_3d_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv3D(32, (3, 3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Conv3D(128, (3, 3, 3), activation='relu'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Conv3D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 3 from 2 for '{{node sequential_1_1/conv3d_5_1/convolution}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](sequential_1_1/batch_normalization_4_1/batchnorm/add_1, sequential_1_1/conv3d_5_1/convolution/ReadVariableOp)' with input shapes: [?,2,26,26,64], [3,3,3,64,128].\u001b[0m\n\nArguments received by Conv3D.call():\n  • inputs=tf.Tensor(shape=(None, 2, 26, 26, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (FRAME_COUNT, IMAGE_SIZE, IMAGE_SIZE, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m build_3d_cnn(input_shape, NUM_CLASSES)\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/naveenjadi/Desktop/naveen/naveen_experiments/model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_x, test_y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/navy_auto/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/navy_auto/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Conv3D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 3 from 2 for '{{node sequential_1_1/conv3d_5_1/convolution}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](sequential_1_1/batch_normalization_4_1/batchnorm/add_1, sequential_1_1/conv3d_5_1/convolution/ReadVariableOp)' with input shapes: [?,2,26,26,64], [3,3,3,64,128].\u001b[0m\n\nArguments received by Conv3D.call():\n  • inputs=tf.Tensor(shape=(None, 2, 26, 26, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "input_shape = (FRAME_COUNT, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "model = build_3d_cnn(input_shape, NUM_CLASSES)\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.2,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint('/Users/naveenjadi/Desktop/naveen/naveen_experiments/model.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_x, test_y)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navy_auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
